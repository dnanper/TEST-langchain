{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMBAmQNa/S7mcCtu8QXvsh6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dnanper/TEST-langchain/blob/main/test02_prompt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cjKMvcS1SgQM"
      },
      "outputs": [],
      "source": [
        "!pip install -U langchain-core>=0.3.47 langchain-openai>=0.3.9 langchain-community==0.3.16"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langsmith"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQT1lRNUS7pv",
        "outputId": "0329ca48-7dfc-4edc-8824-26ef84a85c3d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langsmith in /usr/local/lib/python3.11/dist-packages (0.3.42)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith) (3.10.18)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langsmith) (24.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.11/dist-packages (from langsmith) (2.11.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith) (0.23.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langsmith) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langsmith) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langsmith) (4.13.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langsmith) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith) (2.4.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\") or \\\n",
        "    getpass(\"Enter LangSmith API Key: \")\n",
        "\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"langchaintest\""
      ],
      "metadata": {
        "id": "h21Iuei6WVrL"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "os.environ[\"OPENROUTER_API_KEY\"] = os.getenv(\"OPENROUTER_API_KEY\") or getpass(\n",
        "    \"Enter OpenRouter API Key: \"\n",
        ")\n",
        "\n",
        "openrouter_model = \"deepseek/deepseek-r1:free\""
      ],
      "metadata": {
        "id": "hdCZvg9pWzQ2"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "Answer the user's query based on the context below.\n",
        "If you cannot answer the question using the\n",
        "provided information answer with \"I don't know\".\n",
        "\n",
        "Context: {context}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "LlFeatkVTsXd"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", prompt),\n",
        "    (\"user\", \"{query}\"),\n",
        "])"
      ],
      "metadata": {
        "id": "5hK2k9AjV61K"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template.input_variables"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bhzBiqVXdk4",
        "outputId": "4f36a34d-f190-40f7-a5be-705ca8c660ec"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['context', 'query']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template.messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3cmeHz5XfZ_",
        "outputId": "9b184daf-e51d-41ed-b6d0-87284272fa6e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='\\nAnswer the user\\'s query based on the context below.\\nIf you cannot answer the question using the\\nprovided information answer with \"I don\\'t know\".\\n\\nContext: {context}\\n'), additional_kwargs={}),\n",
              " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['query'], input_types={}, partial_variables={}, template='{query}'), additional_kwargs={})]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import HumanMessagePromptTemplate, SystemMessagePromptTemplate"
      ],
      "metadata": {
        "id": "SsQseALsXiNf"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template_2 = ChatPromptTemplate.from_messages([\n",
        "    SystemMessagePromptTemplate.from_template(prompt),\n",
        "    HumanMessagePromptTemplate.from_template(\"{query}\")\n",
        "])"
      ],
      "metadata": {
        "id": "kLeBi8v3XsnH"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template_2.input_variables"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmRRA68PYrug",
        "outputId": "71f1d7e3-f6af-4a7e-f2d7-ade1e50fc8fb"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['context', 'query']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "llm = ChatOpenAI(\n",
        "    temperature=0.0,\n",
        "    api_key = os.getenv(\"OPENROUTER_API_KEY\"),\n",
        "    base_url = \"https://openrouter.ai/api/v1\",\n",
        "    model=openrouter_model\n",
        "    )"
      ],
      "metadata": {
        "id": "FWw4CTbgYwj2"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = (\n",
        "    {\n",
        "        \"query\": lambda x: x[\"query\"],\n",
        "        \"context\": lambda x: x[\"context\"]\n",
        "    }\n",
        "    | prompt_template\n",
        "    | llm\n",
        ")"
      ],
      "metadata": {
        "id": "XU9FQDnOZCU3"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context = \"\"\"Aurelio AI is an AI company developing tooling for AI\n",
        "engineers. Their focus is on language AI with the team having strong\n",
        "expertise in building AI agents and a strong background in\n",
        "information retrieval.\n",
        "\n",
        "The company is behind several open source frameworks, most notably\n",
        "Semantic Router and Semantic Chunkers. They also have an AI\n",
        "Platform providing engineers with tooling to help them build with\n",
        "AI. Finally, the team also provides development services to other\n",
        "organizations to help them bring their AI tech to market.\n",
        "\n",
        "Aurelio AI became LangChain Experts in September 2024 after a long\n",
        "track record of delivering AI solutions built with the LangChain\n",
        "ecosystem.\"\"\"\n",
        "\n",
        "query = \"what does Aurelio AI do?\""
      ],
      "metadata": {
        "id": "JIyMJzTmZYG2"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline.invoke({\n",
        "    \"query\": query,\n",
        "    \"context\": context\n",
        "    })"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02Po55ttZhNt",
        "outputId": "8bdf8e12-1f38-42f5-cf4a-c0ae2a6faa1b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Aurelio AI is an AI company that develops tooling for AI engineers, with a focus on language AI. They specialize in building AI agents and have expertise in information retrieval. The company is known for open-source frameworks like **Semantic Router** and **Semantic Chunkers**, and they offer an **AI Platform** to help engineers build AI solutions. Additionally, Aurelio AI provides development services to assist organizations in bringing their AI technologies to market. They are also recognized as **LangChain Experts** (as of September 2024) for their work with the LangChain ecosystem.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 343, 'prompt_tokens': 187, 'total_tokens': 530, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'deepseek/deepseek-r1:free', 'system_fingerprint': None, 'id': 'gen-1747890682-WCFTWpupU7PTMfsswRSs', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--d52665a8-0fe3-46d3-a3a9-2fdda9429e02-0', usage_metadata={'input_tokens': 187, 'output_tokens': 343, 'total_tokens': 530, 'input_token_details': {}, 'output_token_details': {}})"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Few Shot"
      ],
      "metadata": {
        "id": "Aptk2lp8o7Mu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"human\", \"{input}\"),\n",
        "    (\"ai\", \"{output}\"),\n",
        "])"
      ],
      "metadata": {
        "id": "irkf2MrbZzw1"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_examples = [\n",
        "    {\"input\": \"Here is query #1\", \"output\": \"Here is the answer #1\"},\n",
        "    {\"input\": \"Here is query #2\", \"output\": \"Here is the answer #2\"},\n",
        "    {\"input\": \"Here is query #3\", \"output\": \"Here is the answer #3\"},\n",
        "]\n"
      ],
      "metadata": {
        "id": "Ds6t-RtSpfwh"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import FewShotChatMessagePromptTemplate"
      ],
      "metadata": {
        "id": "vwJGXycypjNp"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fewshot_prompt = FewShotChatMessagePromptTemplate(\n",
        "    example_prompt=example_prompt,\n",
        "    examples=sample_examples\n",
        ")\n",
        "# here is the formatted prompt\n",
        "print(fewshot_prompt.format())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4helTMGpsdY",
        "outputId": "0fbcb24c-6717-48cc-d80e-ec7fd2d56b05"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: Here is query #1\n",
            "AI: Here is the answer #1\n",
            "Human: Here is query #2\n",
            "AI: Here is the answer #2\n",
            "Human: Here is query #3\n",
            "AI: Here is the answer #3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_system_prompt = \"\"\"\n",
        "Answer the user's query based on the context below.\n",
        "If you cannot answer the question using the\n",
        "provided information answer with \"I don't know\".\n",
        "\n",
        "Always answer in markdown format. When doing so please\n",
        "provide headers, short summaries, follow with bullet\n",
        "points, then conclude.\n",
        "\n",
        "Context: {context}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Ucxs6H6Tp2PY"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template_2.messages[0].prompt.template = new_system_prompt\n",
        "prompt_template_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OneTjA6tqAKf",
        "outputId": "3fbd5a0b-4a08-4f5b-ffc6-3f00855ab443"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['context', 'query'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='\\nAnswer the user\\'s query based on the context below.\\nIf you cannot answer the question using the\\nprovided information answer with \"I don\\'t know\".\\n\\nAlways answer in markdown format. When doing so please\\nprovide headers, short summaries, follow with bullet\\npoints, then conclude.\\n\\nContext: {context}\\n'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['query'], input_types={}, partial_variables={}, template='{query}'), additional_kwargs={})])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown"
      ],
      "metadata": {
        "id": "Z-l5XOxkqizg"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "examples = [\n",
        "    {\n",
        "        \"input\": \"Can you explain gravity?\",\n",
        "        \"output\": (\n",
        "            \"\\n## Gravity\\n\\n\"\n",
        "            \"Gravity is one of the fundamental forces in the universe.\\n\\n\"\n",
        "            \"### Discovery\\n\\n\"\n",
        "            \"* Gravity was first discovered by Sir Isaac Newton in the late 17th century.\\n\"\n",
        "            \"* It was said that Newton theorized about gravity after seeing an apple fall from a tree.\\n\\n\"\n",
        "            \"### In General Relativity\\n\\n\"\n",
        "            \"* Gravity is described as the curvature of spacetime.\\n\"\n",
        "            \"* The more massive an object is, the more it curves spacetime.\\n\"\n",
        "            \"* This curvature is what causes objects to fall towards each other.\\n\\n\"\n",
        "            \"### Gravitons\\n\\n\"\n",
        "            \"* Gravitons are hypothetical particles that mediate the force of gravity.\\n\"\n",
        "            \"* They have not yet been detected.\\n\\n\"\n",
        "            \"**To conclude**, Gravity is a fascinating topic and has been studied extensively since the time of Newton.\\n\\n\"\n",
        "        )\n",
        "    },\n",
        "    {\n",
        "        \"input\": \"What is the capital of France?\",\n",
        "        \"output\": (\n",
        "            \"\\n## France\\n\\n\"\n",
        "            \"The capital of France is Paris.\\n\\n\"\n",
        "            \"### Origins\\n\\n\"\n",
        "            \"* The name Paris comes from the Latin word \\\"Parisini\\\" which referred to a Celtic people living in the area.\\n\"\n",
        "            \"* The Romans named the city Lutetia, which means \\\"the place where the river turns\\\".\\n\"\n",
        "            \"* The city was renamed Paris in the 3rd century BC by the Celtic-speaking Parisii tribe.\\n\\n\"\n",
        "            \"**To conclude**, Paris is highly regarded as one of the most beautiful cities in the world and is one of the world's greatest cultural and economic centres.\\n\\n\"\n",
        "        )\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "LvqqHsI-qwP1"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fewshot_prompt = FewShotChatMessagePromptTemplate(\n",
        "    example_prompt=example_prompt,\n",
        "    examples=examples\n",
        ")"
      ],
      "metadata": {
        "id": "nfppu30MqxAW"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(Markdown(fewshot_prompt.format()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 594
        },
        "id": "RxIrnwBbrMe3",
        "outputId": "314ee62e-0050-48cb-e392-502b6e5ec0af"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Human: Can you explain gravity?\nAI: \n## Gravity\n\nGravity is one of the fundamental forces in the universe.\n\n### Discovery\n\n* Gravity was first discovered by Sir Isaac Newton in the late 17th century.\n* It was said that Newton theorized about gravity after seeing an apple fall from a tree.\n\n### In General Relativity\n\n* Gravity is described as the curvature of spacetime.\n* The more massive an object is, the more it curves spacetime.\n* This curvature is what causes objects to fall towards each other.\n\n### Gravitons\n\n* Gravitons are hypothetical particles that mediate the force of gravity.\n* They have not yet been detected.\n\n**To conclude**, Gravity is a fascinating topic and has been studied extensively since the time of Newton.\n\n\nHuman: What is the capital of France?\nAI: \n## France\n\nThe capital of France is Paris.\n\n### Origins\n\n* The name Paris comes from the Latin word \"Parisini\" which referred to a Celtic people living in the area.\n* The Romans named the city Lutetia, which means \"the place where the river turns\".\n* The city was renamed Paris in the 3rd century BC by the Celtic-speaking Parisii tribe.\n\n**To conclude**, Paris is highly regarded as one of the most beautiful cities in the world and is one of the world's greatest cultural and economic centres.\n\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now prompt template use different system prompt, and also add fewshot_prompt\n",
        "prompt_template_fewshot = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", new_system_prompt),\n",
        "    fewshot_prompt,\n",
        "    (\"human\", \"{query}\"),\n",
        "])"
      ],
      "metadata": {
        "id": "CzIu1RDUr4cv"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_fewshot = (\n",
        "    {\n",
        "        \"query\": lambda x : x[\"query\"],\n",
        "        \"context\": lambda x : x[\"context\"]\n",
        "    }\n",
        "    | prompt_template_fewshot\n",
        "    | llm\n",
        ")"
      ],
      "metadata": {
        "id": "gKLlk3eCrUBO"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fs_out = pipeline_fewshot.invoke({\n",
        "    \"query\": query,\n",
        "    \"context\": context\n",
        "}).content\n",
        "display(Markdown(fs_out))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "pydxOe8Lt2Fr",
        "outputId": "54c45a2a-677f-4216-9f20-e8065541ce3b"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Aurelio AI Overview  \nAurelio AI is an AI company specializing in tools and solutions for AI engineers, with a focus on language-based AI technologies.\n\n### Core Focus Areas  \n- **Language AI Development**: Expertise in building AI agents and information retrieval systems.  \n- **Open-Source Frameworks**: Created tools like **Semantic Router** (for dynamic decision-making in AI workflows) and **Semantic Chunkers** (for context-aware text processing).  \n- **AI Platform**: Provides engineers with tooling to streamline AI development.  \n- **Development Services**: Helps organizations commercialize their AI technologies.  \n\n### Recognition  \n- Named **LangChain Experts** (September 2024) for their proven track record in delivering solutions using the LangChain ecosystem.  \n\n**To conclude**, Aurelio AI bridges advanced language AI research with practical engineering applications, offering both open-source tools and tailored development services."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### COT"
      ],
      "metadata": {
        "id": "jetsFOH5vgCe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_cot = (\n",
        "    \"How many keystrokes are needed to type the numbers from 1 to 500?\"\n",
        ")\n",
        "\n",
        "cot_system_prompt = \"\"\"\n",
        "Be a helpful assistant and answer the user's question.\n",
        "\n",
        "To answer the question, you must:\n",
        "\n",
        "- List systematically and in precise detail all\n",
        "  subproblems that need to be solved to answer the\n",
        "  question.\n",
        "- Solve each sub problem INDIVIDUALLY and in sequence.\n",
        "- Finally, use everything you have worked through to\n",
        "  provide the final answer.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "0xEM-UeAt7hC"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cot_prompt_template = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", cot_system_prompt),\n",
        "    (\"user\", \"{query}\"),\n",
        "])\n",
        "cot_pipeline = cot_prompt_template | llm"
      ],
      "metadata": {
        "id": "1VSIOxS4vrTR"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cot_result = cot_pipeline.invoke({\"query\": query_cot}).content\n",
        "display(Markdown(cot_result))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "mGKOd5AWv59Q",
        "outputId": "43f287db-7fdd-4d9f-be45-aa390c148801"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "To determine the total number of keystrokes required to type the numbers from 1 to 500, we analyze the problem in three parts:\n\n1. **Single-digit numbers (1–9):**  \n   - **Count:** 9 numbers (1 to 9).  \n   - **Keystrokes per number:** 1.  \n   - **Total:** \\(9 \\times 1 = 9\\) keystrokes.  \n\n2. **Two-digit numbers (10–99):**  \n   - **Count:** 90 numbers (10 to 99).  \n   - **Keystrokes per number:** 2.  \n   - **Total:** \\(90 \\times 2 = 180\\) keystrokes.  \n\n3. **Three-digit numbers (100–500):**  \n   - **Count:** 401 numbers (100 to 500, inclusive).  \n   - **Keystrokes per number:** 3.  \n   - **Total:** \\(401 \\times 3 = 1,\\!203\\) keystrokes.  \n\n**Final Calculation:**  \n\\[\n9 \\, (\\text{single-digit}) + 180 \\, (\\text{two-digit}) + 1,\\!203 \\, (\\text{three-digit}) = \\boxed{1,\\!392} \\, \\text{keystrokes}.\n\\]\n\n**Answer:**  \n1,392 keystrokes are needed to type the numbers from 1 to 500."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dLIAYLuVv7l4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}