{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNow2h8hmclZ1JHFJko9jC3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dnanper/TEST-langchain/blob/main/test04_agent_with_toolexecutor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0DItsfTTZlJp"
      },
      "outputs": [],
      "source": [
        "!pip install -U langchain-core>=0.3.47 langchain-openai>=0.3.9 langchain-community==0.3.16"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langsmith"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ene7912aDoF",
        "outputId": "43a9a131-a59b-495f-9377-3c0ad3f7cd1b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langsmith in /usr/local/lib/python3.11/dist-packages (0.3.42)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith) (3.10.18)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langsmith) (24.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.11/dist-packages (from langsmith) (2.11.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith) (0.23.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langsmith) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langsmith) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langsmith) (4.13.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langsmith) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith) (2.4.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\") or \\\n",
        "    getpass(\"Enter LangSmith API Key: \")\n",
        "\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"langchaintest\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZfMEBSpaOOs",
        "outputId": "bd3665c8-e816-4b1c-d428-e9ac3e39b296"
      },
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter LangSmith API Key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "os.environ[\"OPENROUTER_API_KEY\"] = os.getenv(\"OPENROUTER_API_KEY\") or getpass(\n",
        "    \"Enter OpenRouter API Key: \"\n",
        ")\n",
        "\n",
        "openrouter_model = \"deepseek/deepseek-r1:free\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zy4uyZL-adJ0",
        "outputId": "195f30b7-aadf-4d34-922e-f71506821749"
      },
      "execution_count": 4,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter OpenRouter API Key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "llm = ChatOpenAI(\n",
        "    temperature=0.0,\n",
        "    api_key = os.getenv(\"OPENROUTER_API_KEY\"),\n",
        "    base_url = \"https://openrouter.ai/api/v1\",\n",
        "    model=openrouter_model\n",
        "    )"
      ],
      "metadata": {
        "id": "0CjVNel0akcL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.tools import tool\n",
        "\n",
        "@tool\n",
        "def add(x:float, y:float) -> float:\n",
        "  \"\"\"Add 'x' and 'y'.\"\"\"\n",
        "  return x+y\n",
        "\n",
        "@tool\n",
        "def multiply(x:float, y:float) -> float:\n",
        "  \"\"\"Multiply 'x' and 'y'.\"\"\"\n",
        "  return x*y\n",
        "\n",
        "@tool\n",
        "def exponentiate(x: float, y: float) -> float:\n",
        "    \"\"\"Raise 'x' to the power of 'y'.\"\"\"\n",
        "    return x ** y\n",
        "\n",
        "@tool\n",
        "def subtract(x: float, y: float) -> float:\n",
        "    \"\"\"Subtract 'x' from 'y'.\"\"\"\n",
        "    return y - x"
      ],
      "metadata": {
        "id": "Oq2OrLkEamCD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "add"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQnanrN4_DYz",
        "outputId": "70104452-66b7-4dce-d676-be7c25adc034"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StructuredTool(name='add', description=\"Add 'x' and 'y'.\", args_schema=<class 'langchain_core.utils.pydantic.add'>, func=<function add at 0x7bba658d22a0>)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "add.args_schema.model_json_schema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JH3P4sjf_K6r",
        "outputId": "30547c32-f456-450e-a372-3c3dd46325c5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'description': \"Add 'x' and 'y'.\",\n",
              " 'properties': {'x': {'title': 'X', 'type': 'number'},\n",
              "  'y': {'title': 'Y', 'type': 'number'}},\n",
              " 'required': ['x', 'y'],\n",
              " 'title': 'add',\n",
              " 'type': 'object'}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "llm_output_string = \"{\\\"x\\\": 5, \\\"y\\\": 2}\"  # this is the output from the LLM\n",
        "llm_output_dict = json.loads(llm_output_string)  # load as dictionary\n",
        "llm_output_dict #ket qua cuoi cung ma LLM tra ve"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfLv6G3o_eDj",
        "outputId": "0a6e720e-a5ad-4740-c27a-f5555e40ab5c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'x': 5, 'y': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "exponentiate.func(**llm_output_dict) # cho vao tool executor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1ue-6u9Aos4",
        "outputId": "4d551e54-93ee-455f-afc6-2bc9e5e20a71"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder # cho scratchpad"
      ],
      "metadata": {
        "id": "D96gJm3pAvZJ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\",  (\n",
        "        \"You're a helpful assistant. When answering a user's question \"\n",
        "        \"you should first use one of the tools provided. After using a \"\n",
        "        \"tool the tool output will be provided in the \"\n",
        "        \"'scratchpad' below. If you have an answer in the \"\n",
        "        \"scratchpad you should not use any more tools and \"\n",
        "        \"instead answer directly to the user.\"\n",
        "    )),\n",
        "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "    (\"human\", \"{input}\"),\n",
        "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
        "])"
      ],
      "metadata": {
        "id": "PVGOxUBvBDbR"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables.base import RunnableSerializable"
      ],
      "metadata": {
        "id": "WXywkJoOBo-J"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [add, multiply, exponentiate, subtract]"
      ],
      "metadata": {
        "id": "V5HHxrk7B4qY"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent: RunnableSerializable = (\n",
        "  {\n",
        "      \"input\": lambda x : x[\"input\"],\n",
        "      \"chat_history\": lambda x : x[\"chat_history\"],\n",
        "      \"agent_scratchpad\": lambda x : x.get(\"agent_scratchpad\", [])\n",
        "  }\n",
        "  | prompt\n",
        "  | llm.bind_tools(tools, tool_choice=\"any\") # must choose tool\n",
        ")"
      ],
      "metadata": {
        "id": "3MAQsaXJB7Pv"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tool_call = agent.invoke({\"input\": \"What is 10 + 10\", \"chat_history\": []}) -> không thực hiện được do openrouter api không cho phép tool use\n",
        "# tool_call\n",
        "from langchain_core.messages import AIMessage\n",
        "tool_call = AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_SPRcOwtqvcSRQdLaIx1U3ZBN', 'function': {'arguments': '{\"x\":10,\"y\":10}', 'name': 'add'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 197, 'total_tokens': 215, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bd83329f63', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-47a97ee0-09e7-449b-8312-7e4cf524ae7d-0', tool_calls=[{'name': 'add', 'args': {'x': 10, 'y': 10}, 'id': 'call_SPRcOwtqvcSRQdLaIx1U3ZBN', 'type': 'tool_call'}], usage_metadata={'input_tokens': 197, 'output_tokens': 18, 'total_tokens': 215, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})\n",
        "\"\"\"\n",
        "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_SPRcOwtqvcSRQdLaIx1U3ZBN', 'function': {'arguments': '{\"x\":10,\"y\":10}', 'name': 'add'}, 'type': 'function'}],\n",
        "'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 197, 'total_tokens': 215, 'completion_tokens_details':\n",
        "{'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
        "'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bd83329f63', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-47a97ee0-09e7-449b-8312-7e4cf524ae7d-0',\n",
        "tool_calls=[{'name': 'add', 'args': {'x': 10, 'y': 10}, 'id': 'call_SPRcOwtqvcSRQdLaIx1U3ZBN', 'type': 'tool_call'}], usage_metadata={'input_tokens': 197, 'output_tokens': 18,\n",
        "'total_tokens': 215, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "FUZdYIqiDFTv",
        "outputId": "600e67b5-07bf-4ca6-812e-de2a5c26cd97"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nAIMessage(content=\\'\\', additional_kwargs={\\'tool_calls\\': [{\\'id\\': \\'call_SPRcOwtqvcSRQdLaIx1U3ZBN\\', \\'function\\': {\\'arguments\\': \\'{\"x\":10,\"y\":10}\\', \\'name\\': \\'add\\'}, \\'type\\': \\'function\\'}], \\n\\'refusal\\': None}, response_metadata={\\'token_usage\\': {\\'completion_tokens\\': 18, \\'prompt_tokens\\': 197, \\'total_tokens\\': 215, \\'completion_tokens_details\\': \\n{\\'accepted_prediction_tokens\\': 0, \\'audio_tokens\\': 0, \\'reasoning_tokens\\': 0, \\'rejected_prediction_tokens\\': 0}, \\'prompt_tokens_details\\': {\\'audio_tokens\\': 0, \\'cached_tokens\\': 0}}, \\n\\'model_name\\': \\'gpt-4o-mini-2024-07-18\\', \\'system_fingerprint\\': \\'fp_bd83329f63\\', \\'finish_reason\\': \\'tool_calls\\', \\'logprobs\\': None}, id=\\'run-47a97ee0-09e7-449b-8312-7e4cf524ae7d-0\\', \\ntool_calls=[{\\'name\\': \\'add\\', \\'args\\': {\\'x\\': 10, \\'y\\': 10}, \\'id\\': \\'call_SPRcOwtqvcSRQdLaIx1U3ZBN\\', \\'type\\': \\'tool_call\\'}], usage_metadata={\\'input_tokens\\': 197, \\'output_tokens\\': 18, \\n\\'total_tokens\\': 215, \\'input_token_details\\': {\\'audio\\': 0, \\'cache_read\\': 0}, \\'output_token_details\\': {\\'audio\\': 0, \\'reasoning\\': 0}})\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "vì ta đã đặt là \"any\" cho tool choice nên luôn bắt buộc llm response bằng tool. Do đó content = empty vì field này chỉ dành cho Natural Language\n",
        "để tìm tool output, ta cần check tool_call:\n",
        "\"\"\"\n",
        "tool_call.tool_calls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfwtQOz0DFsO",
        "outputId": "d791ed18-5bfa-4d60-bbef-e63bb68a8109"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'name': 'add',\n",
              "  'args': {'x': 10, 'y': 10},\n",
              "  'id': 'call_SPRcOwtqvcSRQdLaIx1U3ZBN',\n",
              "  'type': 'tool_call'}]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "tuy nhiên, LLM không tích hợp sẵn executor, nên dù có implement của hàm và các args truyền vào cho nó, vẫn không thể thực hiện hàm\n",
        "ta cần tự viết phần thực hiện hàm\n",
        "Thực hiện tool cần 2 bước:\n",
        " - maping tên hàm mà LLM chọn (sinh ra) -> hàm đó\n",
        " - thực hiện hàm với các args được sinh\n",
        "\"\"\"\n",
        "# create tool name to function mapping\n",
        "name2tool = {tool.name: tool.func for tool in tools}"
      ],
      "metadata": {
        "id": "5Wo6hbF_EC2d"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# execute\n",
        "tool_exec_content = name2tool[tool_call.tool_calls[0][\"name\"]](\n",
        "    **tool_call.tool_calls[0][\"args\"]\n",
        ")\n",
        "tool_exec_content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYZvFBetFAjL",
        "outputId": "a39bbacf-77ee-4526-9be7-8d1734364847"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# outpt: 20 -> có nghĩa là đã thực hiện hàm"
      ],
      "metadata": {
        "id": "0Rk-RULRFgHM"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import ToolMessage\n",
        "\n",
        "tool_exec = ToolMessage(\n",
        "    content=f\"The {tool_call.tool_calls[0]['name']} tool returned {tool_exec_content}\",\n",
        "    tool_call_id=tool_call.tool_calls[0][\"id\"]\n",
        ")\n",
        "tool_exec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I81_-XCDFtbb",
        "outputId": "2d5ced27-77b2-4e4a-dce9-9e8f372fc022"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ToolMessage(content='The add tool returned 20', tool_call_id='call_SPRcOwtqvcSRQdLaIx1U3ZBN')"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# out = agent.invoke({\n",
        "#     \"input\": \"What is 10 + 10\",\n",
        "#     \"chat_history\": [],\n",
        "#     \"agent_scratchpad\": [tool_call, tool_exec] # vì sao lại truyền vào scratchpad? ở đây, scratchpad dùng để lưu mọi hoạt động của LLM, ta coi như LLM của mình đã tích hợp tool\n",
        "                                                 # executor, đã sinh ra tool_call và sau đó thực hiện những gì được gọi trong tool_call và trả về tool_exec\n",
        "                                                 # do đó, srcratchpad sẽ gồm 2 thông tin đó\n",
        "                                                 # tóm lại, ta đã mô phỏng việc execute tool ở ngoài, và truyền lại output vào llm\n",
        "# })\n",
        "\"\"\"\n",
        "NotFoundError: Error code:\n",
        "404 - {'error': {'message': 'No endpoints found that support tool use. To learn more about provider routing, visit: https://openrouter.ai/docs/provider-routing', 'code': 404}}\n",
        "\"\"\"\n",
        "out = AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_mbzS6t3YlNoyPf6jihCVAhmc', 'function': {'arguments': '{\"x\":10,\"y\":10}', 'name': 'add'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 227, 'total_tokens': 245, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bd83329f63', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-bf39d855-dd41-4cdc-8247-5671cd4fdd6b-0', tool_calls=[{'name': 'add', 'args': {'x': 10, 'y': 10}, 'id': 'call_mbzS6t3YlNoyPf6jihCVAhmc', 'type': 'tool_call'}], usage_metadata={'input_tokens': 227, 'output_tokens': 18, 'total_tokens': 245, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ],
      "metadata": {
        "id": "IviUvBF0G4Pq"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z005ZMO_G_qJ",
        "outputId": "f5d9f217-77bf-4db0-dfdc-9d8181ddf256"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_mbzS6t3YlNoyPf6jihCVAhmc', 'function': {'arguments': '{\"x\":10,\"y\":10}', 'name': 'add'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 227, 'total_tokens': 245, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bd83329f63', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-bf39d855-dd41-4cdc-8247-5671cd4fdd6b-0', tool_calls=[{'name': 'add', 'args': {'x': 10, 'y': 10}, 'id': 'call_mbzS6t3YlNoyPf6jihCVAhmc', 'type': 'tool_call'}], usage_metadata={'input_tokens': 227, 'output_tokens': 18, 'total_tokens': 245, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dù đã có kết quả trong scratchpad, output vẫn không chứa \"20\" do llm bị bắt buộc phải sử dụng tool, và chưa có tool nào cho phép nó lấy final answer\n",
        "# ta sẽ code tool đấy\n",
        "@tool\n",
        "def final_answer(answer: str, tools_used: list[str]) -> str:\n",
        "    \"\"\"\n",
        "    Use this tool to provide a final answer to the user.\n",
        "    The answer should be in natural language as this will be provided\n",
        "    to the user directly. The tools_used must include a list of tool\n",
        "    names that were used within the `scratchpad`.\n",
        "    \"\"\"\n",
        "    return {\"answer\": answer, \"tools_used\": tools_used}"
      ],
      "metadata": {
        "id": "0g_3Syc4HNnZ"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [final_answer, add, subtract, multiply, exponentiate]\n",
        "# we need to update our name2tool mapping too\n",
        "name2tool = {tool.name: tool.func for tool in tools}"
      ],
      "metadata": {
        "id": "zpjngrbEItSR"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent: RunnableSerializable = (\n",
        "    {\n",
        "        \"input\": lambda x: x[\"input\"],\n",
        "        \"chat_history\": lambda x: x[\"chat_history\"],\n",
        "        \"agent_scratchpad\": lambda x: x.get(\"agent_scratchpad\", [])\n",
        "    }\n",
        "    | prompt\n",
        "    | llm.bind_tools(tools, tool_choice=\"any\")  # we're forcing tool use again\n",
        ")"
      ],
      "metadata": {
        "id": "ZJd9sZVNIwqX"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tool_call = agent.invoke({\"input\": \"What is 10 + 10\", \"chat_history\": []})\n",
        "# tool_call.tool_calls # với thông tin hiện tại, llm sẽ vẫn chỉ sinh tool call chứa add, chưa có final_answer\n",
        "# [{'name': 'add',\n",
        "#   'args': {'x': 10, 'y': 10},\n",
        "#   'id': 'call_gYc9NADUc97rn13XMiNXrF12',\n",
        "#   'type': 'tool_call'}]"
      ],
      "metadata": {
        "id": "2WNzj28HI3fh"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tool_out = name2tool[tool_call.tool_calls[0][\"name\"]](\n",
        "    **tool_call.tool_calls[0][\"args\"]\n",
        ")\n",
        "\n",
        "tool_exec = ToolMessage(\n",
        "    content=f\"The {tool_call.tool_calls[0]['name']} tool returned {tool_out}\",\n",
        "    tool_call_id=tool_call.tool_calls[0][\"id\"]\n",
        ")\n",
        "\n",
        "# out = agent.invoke({\n",
        "#     \"input\": \"What is 10 + 10\",\n",
        "#     \"chat_history\": [],\n",
        "#     \"agent_scratchpad\": [tool_call, tool_exec]\n",
        "# })\n",
        "# lần gọi thứ 2, agent có thông tin: tool_call đầu tiên (chứa add), tool_exec với kết quả là 20\n",
        "# đồng thời, nó có tool final_answer trong tool set, nên sẽ sử dụng tool final_answer ở lần response này\n",
        "out = AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_LVqTyA6lpOpAhNIlq10TKqjg', 'function': {'arguments': '{\"answer\":\"10 + 10 equals 20.\",\"tools_used\":[\"functions.add\"]}', 'name': 'final_answer'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 299, 'total_tokens': 327, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bd83329f63', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-5f37367d-83b6-46bb-87f4-4dd773b98caa-0', tool_calls=[{'name': 'final_answer', 'args': {'answer': '10 + 10 equals 20.', 'tools_used': ['functions.add']}, 'id': 'call_LVqTyA6lpOpAhNIlq10TKqjg', 'type': 'tool_call'}], usage_metadata={'input_tokens': 299, 'output_tokens': 28, 'total_tokens': 327, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ],
      "metadata": {
        "id": "FXZNpZQtJIEH"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out.tool_calls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWy1aPJPJe6V",
        "outputId": "75ba1ed2-bb2d-4c9b-9d8b-db60f40edde7"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'name': 'final_answer',\n",
              "  'args': {'answer': '10 + 10 equals 20.', 'tools_used': ['functions.add']},\n",
              "  'id': 'call_LVqTyA6lpOpAhNIlq10TKqjg',\n",
              "  'type': 'tool_call'}]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Because we see the final_answer tool here, we don't pass this back into our agent, and instead,\n",
        "this tells us to stop execution and pass the args output onto our downstream process or user directly:\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "ipnVBz2PKCnk",
        "outputId": "567eab86-e0a0-4436-b6ea-981bf83c8be0"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nBecause we see the final_answer tool here, we don't pass this back into our agent, and instead, \\nthis tells us to stop execution and pass the args output onto our downstream process or user directly:\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out.tool_calls[0][\"args\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSV1icAlJ8qu",
        "outputId": "d959ca15-8e5d-4b50-e2f3-65ce6bd00a21"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer': '10 + 10 equals 20.', 'tools_used': ['functions.add']}"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tóm lại, ta thấy để thêm executor vào luồng hoạt động của LLM, ta phải có bước thực hiện bên ngoài: lấy tool call (name, các args) rồi fetch vào tool executor và thực hiện\n",
        "Sau đó, ta lại tiếp tục lấy output của tool executor để truyền lại vào scratchpad của llm\n",
        "Như vậy, ta có thể code một LLM_with_executor Loop để tự động thực hiện các tác vụ trên"
      ],
      "metadata": {
        "id": "R7IQypbtKKqf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
        "\n",
        "\n",
        "class CustomAgentExecutor:\n",
        "    chat_history: list[BaseMessage]\n",
        "\n",
        "    def __init__(self, max_iterations: int = 3):\n",
        "        self.chat_history = []\n",
        "        self.max_iterations = max_iterations # số lần gọi tool tối đa cho một task\n",
        "        self.agent: RunnableSerializable = (\n",
        "            {\n",
        "                \"input\": lambda x: x[\"input\"],\n",
        "                \"chat_history\": lambda x: x[\"chat_history\"],\n",
        "                \"agent_scratchpad\": lambda x: x.get(\"agent_scratchpad\", [])\n",
        "            }\n",
        "            | prompt\n",
        "            | llm.bind_tools(tools, tool_choice=\"any\")  # we're forcing tool use again\n",
        "        )\n",
        "\n",
        "    def invoke(self, input: str) -> dict:\n",
        "        # invoke the agent but we do this iteratively in a loop until\n",
        "        # reaching a final answer\n",
        "        count = 0\n",
        "        agent_scratchpad = []\n",
        "\n",
        "        ## vòng lặp chính: gọi (invoke) llm dựa trên scratchpad, lấy tool call từ output của nó, thực hiện bên ngoài,\n",
        "        ## rồi fetch lại cho llm toolcall và toolexec (thông qua scracthpad)\n",
        "        while count < self.max_iterations:\n",
        "            # invoke a step for the agent to generate a tool call\n",
        "            tool_call = self.agent.invoke({\n",
        "                \"input\": input,\n",
        "                \"chat_history\": self.chat_history,\n",
        "                \"agent_scratchpad\": agent_scratchpad\n",
        "            })\n",
        "            # add initial tool call to scratchpad\n",
        "            agent_scratchpad.append(tool_call)\n",
        "            # otherwise we execute the tool and add it's output to the agent scratchpad\n",
        "            tool_name = tool_call.tool_calls[0][\"name\"]\n",
        "            tool_args = tool_call.tool_calls[0][\"args\"]\n",
        "            tool_call_id = tool_call.tool_calls[0][\"id\"]\n",
        "            tool_out = name2tool[tool_name](**tool_args)\n",
        "            # add the tool output to the agent scratchpad\n",
        "            tool_exec = ToolMessage(\n",
        "                content=f\"{tool_out}\",\n",
        "                tool_call_id=tool_call_id\n",
        "            )\n",
        "            agent_scratchpad.append(tool_exec)\n",
        "            # add a print so we can see intermediate steps\n",
        "            print(f\"{count}: {tool_name}({tool_args})\")\n",
        "            count += 1\n",
        "            # if the tool call is the final answer tool, we stop\n",
        "            if tool_name == \"final_answer\":\n",
        "                break\n",
        "        # add the final output to the chat history\n",
        "        final_answer = tool_out[\"answer\"]\n",
        "        self.chat_history.extend([\n",
        "            HumanMessage(content=input),\n",
        "            AIMessage(content=final_answer)\n",
        "        ])\n",
        "        # return the final answer in dict form\n",
        "        return json.dumps(tool_out)"
      ],
      "metadata": {
        "id": "Wos5_wXCKAcW"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor = CustomAgentExecutor()"
      ],
      "metadata": {
        "id": "rUW5tFBSLwDk"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# agent_executor.invoke(input=\"What is 10 + 10\")"
      ],
      "metadata": {
        "id": "vH09TuZILxUk"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ppYgmQ-aLzJz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}